{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56bf2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9eab89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ojasg\\AppData\\Local\\Temp\\ipykernel_33096\\3616641571.py:21: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Title', 'Genres'], encoding='latin1', index_col=[0])\n",
      "C:\\Users\\ojasg\\AppData\\Local\\Temp\\ipykernel_33096\\3616641571.py:25: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Gender', \"Age\", \"Occupation\", \"Zipcode\"], encoding='latin1', index_col=[0])\n",
      "C:\\Users\\ojasg\\AppData\\Local\\Temp\\ipykernel_33096\\3616641571.py:57: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file_path, delimiter='::', header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding='latin1', index_col=[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Gender', 'Age', 'Occupation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# TODO: move to dataloader.py\n",
    "\n",
    "def make_unique_ints(df, col):\n",
    "\n",
    "    unique_ids = set(i[col]\n",
    "                        for i in df.to_dict('records'))\n",
    "    ids_to_ints = {j: i for i, j in enumerate(unique_ids)}\n",
    "    new_col = [ids_to_ints[i] for i in df[col]]\n",
    "    return new_col, ids_to_ints\n",
    "\n",
    "\n",
    "def map_unique_ints(df, col, ids_to_ints):\n",
    "    new_col = [ids_to_ints[i] for i in df[col]]\n",
    "    return new_col\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"movieLens/movies.dat\"\n",
    "\n",
    "movies_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Title', 'Genres'], encoding='latin1', index_col=[0])\n",
    "\n",
    "file_path = \"movieLens/users.dat\"\n",
    "\n",
    "users_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Gender', \"Age\", \"Occupation\", \"Zipcode\"], encoding='latin1', index_col=[0])\n",
    "\n",
    "movies_df = movies_df.reset_index()\n",
    "movies_df = movies_df.drop('Title', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "id_maps = []\n",
    "movies_df['ID'], movies_id_map = make_unique_ints(movies_df, 'ID')\n",
    "id_maps.append(movies_id_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "users_df = users_df.reset_index()\n",
    "users_df = users_df.drop('Zipcode', axis=1)\n",
    "\n",
    "for col in users_df.columns:\n",
    "    users_df[col], users_id_map = make_unique_ints(users_df, col)\n",
    "    id_maps.append(users_id_map)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_path = \"movieLens/ratings.dat\"\n",
    "\n",
    "ratings_df = pd.read_csv(file_path, delimiter='::', header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding='latin1', index_col=[0])\n",
    "\n",
    "\n",
    "ratings_df = ratings_df.reset_index()\n",
    "\n",
    "ratings_df['UserID'] = map_unique_ints(ratings_df, 'UserID', id_maps[len(movies_df.columns)-1])\n",
    "ratings_df['MovieID'] = map_unique_ints(ratings_df, 'MovieID', id_maps[0])\n",
    "ratings_df = ratings_df[[\"MovieID\", \"UserID\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "B = np.zeros((len(movies_df), len(users_df)))\n",
    "B[ratings_df['MovieID'], ratings_df['UserID']] = 1\n",
    "\n",
    "\n",
    "\n",
    "movies_df = movies_df.drop(\"ID\", axis=1)\n",
    "users_df = users_df.drop(\"ID\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "movie_Genres = [\n",
    "\"Action\",\n",
    "\"Adventure\",\n",
    "\"Animation\",\n",
    "\"Children\\'s\",\n",
    "\"Comedy\",\n",
    "\"Crime\",\n",
    "\"Documentary\",\n",
    "\"Drama\",\n",
    "\"Fantasy\",\n",
    "\"Film-Noir\",\n",
    "\"Horror\",\n",
    "\"Musical\",\n",
    "\"Mystery\",\n",
    "\"Romance\",\n",
    "\"Sci-Fi\",\n",
    "\"Thriller\",\n",
    "\"War\",\n",
    "\"Western\"\n",
    "]\n",
    "\n",
    "for name in movie_Genres:\n",
    "    movies_df[\"is_\"+name] = movies_df['Genres'].str.contains(name) * 1\n",
    "    assert sum(movies_df[\"is_\"+name]) > 0\n",
    "\n",
    "movies_df = movies_df.drop('Genres', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87460db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f79b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to utility.py\n",
    "# TODO: Check if preprocessor_eps is needed\n",
    "\n",
    "from snsynth import Synthesizer\n",
    "\n",
    "def compute_single_table_synth_data(df, n1, synthesizer='patectgan', epsilon=3, preprocessor_eps=0.5):\n",
    "\n",
    "    if synthesizer == 'patectgan':\n",
    "        synth = Synthesizer.create(\"patectgan\", epsilon=epsilon, verbose=True)\n",
    "        synth.fit(df, preprocessor_eps=preprocessor_eps)\n",
    "        dat = synth.sample(n1)\n",
    "        return dat\n",
    "    elif synthesizer == 'dpctgan':\n",
    "        synth = Synthesizer.create(\"dpctgan\", epsilon=epsilon, verbose=True)\n",
    "        synth.fit(df, preprocessor_eps=preprocessor_eps)\n",
    "        dat = synth.sample(n1)\n",
    "        return dat\n",
    "    elif synthesizer == 'mst':\n",
    "        synth = Synthesizer.create(\"mst\", epsilon=epsilon, verbose=True)\n",
    "        synth.fit(df, preprocessor_eps=preprocessor_eps)\n",
    "        dat = synth.sample(n1)\n",
    "        return dat\n",
    "    elif synthesizer == 'aim':\n",
    "        synth = Synthesizer.create(\"aim\", epsilon=epsilon, verbose=True)\n",
    "        synth.fit(df, preprocessor_eps=preprocessor_eps)\n",
    "        dat = synth.sample(n1)\n",
    "        return dat\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b85dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.rename(columns={'MovieID': 'ID_1'}, inplace=True)\n",
    "ratings_df.rename(columns={'UserID': 'ID_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15438dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7e3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = movies_df\n",
    "df2 = users_df \n",
    "relationship = ratings_df\n",
    "\n",
    "df1_ordinal_cols = list(movies_df.columns)\n",
    "df2_ordinal_cols = list(users_df.columns)\n",
    "\n",
    "synth = 'mst'\n",
    "\n",
    "epsilon = 3.0\n",
    "T = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4eb2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ffbca95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 262144 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n",
      "Fitting with 294 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n"
     ]
    }
   ],
   "source": [
    "n1 = len(df1)\n",
    "n2 = len(df2)\n",
    "d1 = len(df1.columns)\n",
    "d2 = len(df2.columns)\n",
    "\n",
    "\n",
    "\n",
    "#### TODO: This is just for the testing purpose! Increase this number!!!!!\n",
    "n_syn1 = 776\n",
    "n_syn2 = 1208\n",
    "\n",
    "# n_syn1 = n1\n",
    "# n_syn2 = n2\n",
    "\n",
    "df1_synt = compute_single_table_synth_data(df1, n_syn1, synth, epsilon = 1.0)\n",
    "df2_synt = compute_single_table_synth_data(df2, n_syn2, synth, epsilon = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0887909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove np.sort() and check no bug\n",
    "df1_col_dic = {col: {'unique_values': list(np.sort(df1[col].unique())), 'count': len(df1[col].unique())} for col in df1.columns}\n",
    "df2_col_dic = {col: {'unique_values': list(np.sort(df2[col].unique())), 'count': len(df2[col].unique())} for col in df2.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea18aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59804f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-way marginal queries\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0252d6cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# k-way cross features\n",
    "workload_names = []\n",
    "k_way_workload = {}\n",
    "\n",
    "\n",
    "\n",
    "range_low = 0\n",
    "range_high = 0\n",
    "for k1 in range(1,k):\n",
    "    df1_k1_col = list(itertools.combinations(df1.columns, k1))\n",
    "    for k2 in range(1, k-k1+1):\n",
    "        df2_k2_col = list(itertools.combinations(df2.columns, k2))\n",
    "        if k1+k2 == k:\n",
    "            \n",
    "            for col_comb_1 in df1_k1_col:\n",
    "                for col_comb_2 in df2_k2_col:\n",
    "                    \n",
    "                    len_range = 1\n",
    "                    uni_val_1 = []\n",
    "                    \n",
    "                    for col1 in col_comb_1:\n",
    "                        c1 = df1_col_dic[col1]['count']\n",
    "                        uni_val_1.append(c1)\n",
    "                        len_range *= c1\n",
    "                    assert len(uni_val_1) == k1\n",
    "                    \n",
    "                    uni_val_2 = []\n",
    "                    for col2 in col_comb_2:\n",
    "                        c2 = df2_col_dic[col2]['count']\n",
    "                        uni_val_2.append(c2)\n",
    "                        len_range *= c2\n",
    "                    assert len(uni_val_2) == k2\n",
    "                    \n",
    "                    range_high = range_low + len_range - 1 \n",
    "                    workload_names.append((col_comb_1 , col_comb_2))\n",
    "                    k_way_workload[(col_comb_1 , col_comb_2)] = {\"dim_1\": uni_val_1, \"dim_2\": uni_val_2,\"range_low\": range_low, \"range_high\": range_high}\n",
    "                    \n",
    "                    range_low = range_high + 1\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82877daf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# k is a global variable\n",
    "# TODO: rename k. Not a good name for a global variable\n",
    "# TODO: here I assume feature values are {0, 1, 2, ...} (i.e., all features are ordinal encoded).\n",
    "\n",
    "def query_ind(workload, val):\n",
    "    \n",
    "    assert len(workload) == 2 #since only two tables\n",
    "    assert len(workload[0]) + len(workload[1]) == k # k features?\n",
    "    assert len(workload[0]) > 0 and len(workload[1]) > 0 # cross table queries\n",
    "    \n",
    "    assert len(val) == 2\n",
    "    assert len(val[0]) == len(workload[0]) and len(val[1]) == len(workload[1])\n",
    "    \n",
    "    # TODO: add assert making sure val belongs to the unique value set of workload\n",
    "    total_val = val[0] + val[1]\n",
    "    \n",
    "    q_ind = k_way_workload[workload]['range_low']\n",
    "    dim1 = k_way_workload[workload]['dim_1']\n",
    "    dim2 = k_way_workload[workload]['dim_2']\n",
    "    \n",
    "    dim = dim1 + dim2\n",
    "    \n",
    "    total_dim = 1\n",
    "    for i in dim:\n",
    "        total_dim *= i\n",
    "    \n",
    "    # reshape\n",
    "    for i in range(len(total_val)):\n",
    "        total_dim = total_dim/dim[i]\n",
    "        q_ind += total_dim * total_val[i]\n",
    "        \n",
    "    assert total_dim == 1\n",
    "    assert q_ind <= k_way_workload[workload]['range_high']\n",
    "    \n",
    "    return q_ind\n",
    "\n",
    "\n",
    "# example: \n",
    "# a = (('is_War', 'is_Western'), ('Age',)) for k=3\n",
    "# b = [[1,1], [1]] for k=3\n",
    "# query_ind(a, b)\n",
    "\n",
    "def query_ind_df1(workload, val1):\n",
    "    \n",
    "    assert len(workload) == 2 #since only two tables\n",
    "    assert len(workload[0]) + len(workload[1]) == k # k features?\n",
    "    assert len(workload[0]) > 0 and len(workload[1]) > 0 # cross table queries\n",
    "    \n",
    "    assert len(val1) == len(workload[0])\n",
    "    \n",
    "    \n",
    "    q_ind = k_way_workload[workload]['range_low']\n",
    "    dim1 = k_way_workload[workload]['dim_1']\n",
    "    dim2 = k_way_workload[workload]['dim_2']\n",
    "    \n",
    "    dim = dim1 + dim2\n",
    "    \n",
    "    total_dim = 1\n",
    "    for i in dim:\n",
    "        total_dim *= i\n",
    "    \n",
    "    # reshape\n",
    "    for i in range(len(val1)):\n",
    "        total_dim = total_dim/dim[i]\n",
    "        q_ind += total_dim * val1[i]\n",
    "    \n",
    "    q_ind_min = q_ind\n",
    "    q_ind_max = q_ind\n",
    "    \n",
    "    for j in dim2:\n",
    "        total_dim = total_dim/j\n",
    "        q_ind_max += total_dim * (j-1)\n",
    "    \n",
    "    q = [i for i in range(int(q_ind_min), int(q_ind_max + 1))]\n",
    "    \n",
    "    assert max(q) <= k_way_workload[workload]['range_high']\n",
    "    \n",
    "    return q\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def query_ind_df2(workload, val2):\n",
    "    \n",
    "    assert len(workload) == 2 #since only two tables\n",
    "    assert len(workload[0]) + len(workload[1]) == k # k features?\n",
    "    assert len(workload[0]) > 0 and len(workload[1]) > 0 # cross table queries\n",
    "    \n",
    "    assert len(val2) == len(workload[1])\n",
    "    \n",
    "    \n",
    "    q_ind = k_way_workload[workload]['range_low']\n",
    "    dim1 = k_way_workload[workload]['dim_1']\n",
    "    dim2 = k_way_workload[workload]['dim_2']\n",
    "    \n",
    "    total_dim1 = 1\n",
    "    for i in dim1:\n",
    "        total_dim1 *= i\n",
    "    \n",
    "    q_ind_min = 0\n",
    "    q_ind_max = 0\n",
    "    \n",
    "    for j in dim1:\n",
    "        total_dim1 = total_dim1/j\n",
    "        q_ind_max += total_dim1 * (j-1)\n",
    "    q = [i for i in range(int(q_ind_min), int(q_ind_max + 1))]\n",
    "    \n",
    "    \n",
    "    total_dim2 = 1\n",
    "    \n",
    "    for i in dim2:\n",
    "        total_dim2 *= i\n",
    "    \n",
    "    q = [int(i * int(total_dim2)) for i in q]\n",
    "    \n",
    "    \n",
    "    temp = q_ind\n",
    "    for i in range(len(val2)):\n",
    "        total_dim2 = total_dim2/dim2[i]\n",
    "        temp += total_dim2 * val2[i]\n",
    "    \n",
    "    q = [int(i + temp) for i in q]\n",
    "    \n",
    "    assert max(q) <= k_way_workload[workload]['range_high']\n",
    "    return q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bba7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4521a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_workload = workload_names[-1]\n",
    "num_all_queries = k_way_workload[last_workload][\"range_high\"] + 1\n",
    "rand_ans = np.zeros(num_all_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6336cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_queries = k_way_workload[last_workload][\"range_high\"] + 1\n",
    "rand_ans = np.zeros(num_all_queries)\n",
    "\n",
    "for workload_name in k_way_workload:\n",
    "    w = k_way_workload[workload_name]\n",
    "    rand_ans[w['range_low']: (w['range_high']+1)] = 1.0/(w['range_high'] - w['range_low'] + 1)\n",
    "    \n",
    "\n",
    "#import math \n",
    "#assert math.isclose(sum(rand_ans), len(workload_names), rel_tol=1e-9, abs_tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2e11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b15ad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba3cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check this function. Add some testings\n",
    "def remove_excess_rows(df, column, k):\n",
    "    counts = df.groupby(column).cumcount()\n",
    "    return df[counts < k].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79333ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmax = 10 # max number of degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e66ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = remove_excess_rows(relationship, 'ID_1', dmax)\n",
    "relationship = remove_excess_rows(relationship, 'ID_2', dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec51be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b8a3fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_relationship = relationship.shape[0]\n",
    "true_ans = np.zeros(num_all_queries)\n",
    "\n",
    "\n",
    "# TODO: need to improve it!\n",
    "for i in range(num_relationship):\n",
    "    \n",
    "    # TODO: assert ID_1 and ID_2 correspond to index\n",
    "    \n",
    "    ID1 = relationship.iloc[i]['ID_1']\n",
    "    \n",
    "    ID2 = relationship.iloc[i]['ID_2']\n",
    "    \n",
    "    for w in workload_names:\n",
    "        cols1 = w[0]\n",
    "        cols2 = w[1]\n",
    "        v1 = []\n",
    "        for c1 in cols1:\n",
    "            v1.append(df1.iloc[ID1][c1])\n",
    "            \n",
    "        v2 = []\n",
    "        for c2 in cols2:\n",
    "            v2.append(df2.iloc[ID2][c2])\n",
    "        \n",
    "        ind = query_ind(w, [v1,v2])\n",
    "        true_ans[int(ind)] += 1\n",
    "        \n",
    "true_ans = true_ans/num_relationship\n",
    "\n",
    "# import math \n",
    "# assert math.isclose(sum(true_ans), len(workload_names), rel_tol=1e-9, abs_tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86cf921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04cacb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/terranceliu/dp-query-release\n",
    "\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "Functions for converting between concentrated and approximate DP\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def cdp_delta(rho, eps, iterations=1000):\n",
    "    \"\"\"This function finds the optimal value of delta such that rho-CDP implies\n",
    "    (eps, delta)-DP.\n",
    "\n",
    "    Args:\n",
    "        rho (float): Rho\n",
    "        eps (float): Epsilon\n",
    "        iterations (int, optional): Determines the number of iterations to run\n",
    "            binary search\n",
    "    Returns:\n",
    "        delta (float): DELTA.\n",
    "\n",
    "    (Notes) Delta is calculate by finding the optimal alpha in (1, infinity) via binary\n",
    "    search. Note that the optimal alpha is at least (1+eps/rho)/2. Thus we only hit\n",
    "    this constraint when eps<=rho or close to it. This is not an interesting parameter\n",
    "    regime, as you will inherently get large delta in this regime.\n",
    "    \"\"\"\n",
    "    assert rho >= 0\n",
    "    assert eps >= 0\n",
    "    assert iterations > 0\n",
    "    if rho == 0:  # degenerate case\n",
    "        return 0\n",
    "\n",
    "    amin = 1.01  # alpha cannot be due small (numerical stability)\n",
    "    amax = (eps + 1) / (2 * rho) + 2\n",
    "    alpha = None\n",
    "    for _ in range(iterations):\n",
    "        alpha = (amin + amax) / 2\n",
    "        derivative = (2 * alpha - 1) * rho - eps + math.log1p(-1.0 / alpha)\n",
    "        if derivative < 0:\n",
    "            amin = alpha\n",
    "        else:\n",
    "            amax = alpha\n",
    "\n",
    "    delta = math.exp(\n",
    "        (alpha - 1) * (alpha * rho - eps) + alpha * math.log1p(-1 / alpha)\n",
    "    ) / (alpha - 1.0)\n",
    "    delta = min(delta, 1.0)  # delta <= 1\n",
    "    return delta\n",
    "\n",
    "\n",
    "def cdp_eps(rho, delta, iterations=1000):\n",
    "    \"\"\"This function finds the smallest value of eps such that rho-CDP implies\n",
    "    (eps, delta)-DP\n",
    "    Args:\n",
    "        rho (float): Rho\n",
    "        delta (float): Delta\n",
    "        iterations (int, optional): Determines the number of iterations to run binary\n",
    "            search\n",
    "    Returns:\n",
    "        epsmax (float): Epsilon.\n",
    "    \"\"\"\n",
    "    assert rho >= 0\n",
    "    assert delta > 0\n",
    "    assert iterations > 0\n",
    "    if delta >= 1 or rho == 0:  # if delta>=1 or rho=0, then anything goes\n",
    "        return 0.0\n",
    "\n",
    "    epsmin = 0.0  # maintain cdp_delta(rho,eps) >= delta\n",
    "    epsmax = rho + 2 * math.sqrt(\n",
    "        rho * math.log(1 / delta)\n",
    "    )  # maintain cdp_delta(rho,eps) <= delta\n",
    "    for _ in range(iterations):\n",
    "        eps = (epsmin + epsmax) / 2\n",
    "        if cdp_delta(rho, eps) <= delta:\n",
    "            epsmax = eps\n",
    "        else:\n",
    "            epsmin = eps\n",
    "\n",
    "    return epsmax\n",
    "\n",
    "\n",
    "def cdp_rho(eps, delta, iterations=1000):\n",
    "    \"\"\"This function finds the smallest rho such that rho-CDP implies (eps, delta)-DP\n",
    "    Args:\n",
    "        eps (float): Epsilon\n",
    "        delta (float): Delta\n",
    "        iterations (int, optional): Determines the number of iterations to run\n",
    "            binary search\n",
    "    Returns:\n",
    "        rhomin (float): Rho.\n",
    "    \"\"\"\n",
    "    assert eps >= 0\n",
    "    assert delta > 0\n",
    "    assert iterations > 0\n",
    "    if delta >= 1:  # if delta >= 1, then anything goes\n",
    "        return 0.0\n",
    "\n",
    "    rhomin = 0.0  # maintain cdp_delta(rho,eps) <= delta\n",
    "    rhomax = eps + 1  # maintain cdp_delta(rhomax,eps) > delta\n",
    "    for _ in range(iterations):\n",
    "        rho = (rhomin + rhomax) / 2\n",
    "        if cdp_delta(rho, eps) <= delta:\n",
    "            rhomin = rho\n",
    "        else:\n",
    "            rhomax = rho\n",
    "\n",
    "    return rhomin\n",
    "\n",
    "\n",
    "def get_per_round_privacy_budget(\n",
    "    epsilon: float, delta: float, num_workloads: int, alpha = None\n",
    "):\n",
    "    rho = cdp_rho(epsilon, delta)\n",
    "    if alpha is None:\n",
    "        eps0 = 2 * rho / num_workloads\n",
    "    else:\n",
    "        eps0 = (2 * rho) / (num_workloads * (alpha**2 + (1 - alpha) ** 2))\n",
    "    eps0 = math.pow(eps0, 0.5)\n",
    "    return eps0, rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8afcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3923467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4c184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdd01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f784f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9beefbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/776 [00:00<00:20, 37.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 776/776 [00:18<00:00, 41.10it/s]\n"
     ]
    }
   ],
   "source": [
    "Q1 = np.zeros((num_all_queries, n_syn1 * n_syn2))\n",
    "\n",
    "for i in tqdm(range(n_syn1)):\n",
    "    row = df1_synt.iloc[i]\n",
    "    #data indices\n",
    "    ind_d = [i*n_syn2 + j for j in range(n_syn2)]\n",
    "    \n",
    "    for w in workload_names:\n",
    "        val = list(row[list(w[0])])\n",
    "        #query indices\n",
    "        ind_q = query_ind_df1(w, val)\n",
    "        \n",
    "        Q1[np.ix_(ind_q, ind_d)] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b23fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147135a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:32<00:00, 37.58it/s]\n"
     ]
    }
   ],
   "source": [
    "Q2 = np.zeros((num_all_queries, n_syn1 * n_syn2))\n",
    "\n",
    "for j in tqdm(range(n_syn2)):\n",
    "    row = df2_synt.iloc[j]\n",
    "    #data indices\n",
    "    ind_d = [i*n_syn2 + j for i in range(n_syn1)]\n",
    "    \n",
    "    for w in workload_names:\n",
    "        val = list(row[list(w[1])])\n",
    "        #query indices\n",
    "        ind_q = query_ind_df2(w, val)\n",
    "        \n",
    "        Q2[np.ix_(ind_q, ind_d)] = 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ab516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i-th row in df1 and j-th row in df2:\n",
    "# i * n_syn2 + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30062de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q = Q1 * Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6652d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 1., 1.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2b0f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(sum(Q)) == (len(workload_names) * n_syn1 * n_syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c5a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0b264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b683de86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_descent(Q, b, a, step_size = 0.01, T_mirror = 50):\n",
    "    # b is a vector whose sum is 1\n",
    "    \n",
    "    Q = np.array(Q)\n",
    "    b = np.array(b)\n",
    "    a = np.array(a)\n",
    "    \n",
    "    assert len(Q[0]) == len(b)\n",
    "    assert len(Q) == len(a)\n",
    "\n",
    "    def mirror_descent_update(x, gradient):\n",
    "        # Choose a suitable step size (e.g., 1/D)\n",
    "\n",
    "        # Perform the Mirror Descent update\n",
    "        numer = x * np.exp(-step_size * gradient)\n",
    "        denom = np.sum(x * np.exp(-step_size * gradient))\n",
    "\n",
    "        updated_x = numer / denom\n",
    "\n",
    "        return updated_x\n",
    "\n",
    "    # Function to compute the gradient of the objective function ||Qb - a||_2^2\n",
    "    def gradient(Q, b, a):\n",
    "        return 2 * Q.T @ (np.matmul(Q, b) - a)\n",
    "\n",
    "    iters = 0\n",
    "\n",
    "    # Mirror Descent iterations\n",
    "    while iters < T:\n",
    "        iters += 1\n",
    "        # Compute the gradient of the objective function\n",
    "        grad = gradient(Q, b, a)\n",
    "        # Update using Mirror Descent\n",
    "        b = mirror_descent_update(b, grad)\n",
    "        # print(\"B update step: \", b)\n",
    "    \n",
    "    return b\n",
    "\n",
    "\n",
    "def GM(inp, rho):\n",
    "    num = len(inp)\n",
    "    out = []\n",
    "    for i in range(num):\n",
    "        val = inp[i] + np.random.normal(0, np.sqrt(2)/(num_relationship * np.sqrt(rho)))\n",
    "        out.append(val)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc44f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expround(b):\n",
    "    N = len(b)\n",
    "    m = np.sum(b)\n",
    "    X = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        X[i] = np.random.exponential(b[i])\n",
    "    # finding the index of top m elements\n",
    "    idx = sorted(range(N), key=lambda i: X[i])[-int(m):]\n",
    "    bu = np.zeros(N)\n",
    "    for i in idx:\n",
    "        bu[i] = 1\n",
    "    return bu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48162e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec0914b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:41<01:07, 33.90s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.89 GiB for an array with shape (937408, 270) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m Q[ind_low:(ind_high\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]:\n\u001b[0;32m     55\u001b[0m             Q_set\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m---> 57\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[43mmirror_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_ans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_mirror\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m n_relationship_synt\n\u001b[0;32m     60\u001b[0m b_round \u001b[38;5;241m=\u001b[39m expround(b)\n",
      "Cell \u001b[1;32mIn[25], line 32\u001b[0m, in \u001b[0;36mmirror_descent\u001b[1;34m(Q, b, a, step_size, T_mirror)\u001b[0m\n\u001b[0;32m     30\u001b[0m iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Compute the gradient of the objective function\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Update using Mirror Descent\u001b[39;00m\n\u001b[0;32m     34\u001b[0m b \u001b[38;5;241m=\u001b[39m mirror_descent_update(b, grad)\n",
      "Cell \u001b[1;32mIn[25], line 24\u001b[0m, in \u001b[0;36mmirror_descent.<locals>.gradient\u001b[1;34m(Q, b, a)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(Q, b, a):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m@\u001b[39m (np\u001b[38;5;241m.\u001b[39mmatmul(Q, b) \u001b[38;5;241m-\u001b[39m a)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.89 GiB for an array with shape (937408, 270) and data type float64"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "two_way_ave_error= []\n",
    "two_way_max_error= []\n",
    "# privacy budget\n",
    "epsilon_relationship_set = [1.0, 4.0, 16.0]\n",
    "\n",
    "delta_relationship = 1e-5\n",
    "\n",
    "# number of iterations\n",
    "T = 5 # was 10, needs to run on my laptop\n",
    "\n",
    "for epsilon_relationship in epsilon_relationship_set:\n",
    "\n",
    "    # number of workloads to compute per iteration\n",
    "    num_workload_ite = 2\n",
    "\n",
    "    epsilon_relationship = epsilon_relationship/(dmax * num_workload_ite)\n",
    "\n",
    "    # convert to RDP\n",
    "    rho_rel = cdp_rho(epsilon_relationship, delta_relationship)\n",
    "\n",
    "    # privacy budget per iteration\n",
    "    per_round_rho_rel = rho_rel / T\n",
    "\n",
    "    # intialization\n",
    "    unselected_workload = [i for i in range(len(workload_names))]\n",
    "    Q_set = []\n",
    "    noisy_ans = []\n",
    "    b = np.ones(n_syn1 * n_syn2) / (n_syn1 * n_syn2)\n",
    "\n",
    "    for t in tqdm(range(T)):\n",
    "\n",
    "        # TODO: use exponential mechanism!!!\n",
    "        # Here I randomly choose 2 workloads\n",
    "        select_workload = random.choices(unselected_workload, k=num_workload_ite)\n",
    "        unselected_workload = [i for i in unselected_workload if i not in select_workload]\n",
    "\n",
    "\n",
    "        for i in select_workload:\n",
    "\n",
    "            curr_workload = workload_names[i]\n",
    "\n",
    "            ind_low, ind_high = k_way_workload[curr_workload]['range_low'], k_way_workload[curr_workload]['range_high']\n",
    "\n",
    "            curr_ans = true_ans[ind_low:(ind_high+1)]\n",
    "\n",
    "            noisy_curr_ans = GM(curr_ans, per_round_rho_rel)\n",
    "\n",
    "            for row in noisy_curr_ans:\n",
    "                noisy_ans.append(row)\n",
    "\n",
    "            for row in Q[ind_low:(ind_high+1)]:\n",
    "                Q_set.append(row.tolist())\n",
    "\n",
    "        b = mirror_descent(Q_set, b, noisy_ans, step_size = 0.01, T_mirror = 50)\n",
    "\n",
    "    b = b * n_relationship_synt\n",
    "    b_round = expround(b)\n",
    "    b_round = b_round.reshape(n_syn1, n_syn2)\n",
    "    relationship_syn = pd.DataFrame(columns=['ID_1', 'ID_2'])\n",
    "\n",
    "    for i in range(n_syn1):\n",
    "        for j in range(n_syn2):\n",
    "            if b_round[i,j] == 1:\n",
    "                new_data = pd.DataFrame([{'ID_1': i, 'ID_2': j}])\n",
    "                relationship_syn = pd.concat([relationship_syn, new_data], ignore_index=True)\n",
    "    \n",
    "    num_relationship_syn = relationship_syn.shape[0]\n",
    "    ans_syn = np.zeros(num_all_queries)\n",
    "\n",
    "    for i in range(num_relationship_syn):\n",
    "\n",
    "        # TODO: assert ID_1 and ID_2 correspond to index\n",
    "\n",
    "        ID1 = relationship_syn.iloc[i]['ID_1']\n",
    "\n",
    "        ID2 = relationship_syn.iloc[i]['ID_2']\n",
    "\n",
    "        for w in workload_names:\n",
    "            cols1 = w[0]\n",
    "            cols2 = w[1]\n",
    "            v1 = []\n",
    "            for c1 in cols1:\n",
    "                v1.append(df1_synt.iloc[ID1][c1])\n",
    "\n",
    "            v2 = []\n",
    "            for c2 in cols2:\n",
    "                v2.append(df2_synt.iloc[ID2][c2])\n",
    "\n",
    "            ind = query_ind(w, [v1,v2])\n",
    "            ans_syn[int(ind)] += 1\n",
    "\n",
    "    ans_syn = ans_syn/num_relationship_syn\n",
    "    \n",
    "    temp1 =100 * np.sum(np.abs(ans_syn - true_ans)) / len(true_ans)\n",
    "    temp2 =100 * np.max(np.abs(ans_syn - true_ans)) / len(true_ans)\n",
    "    \n",
    "    \n",
    "    two_way_ave_error.append(temp1)\n",
    "    two_way_max_error.append(temp2)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1fd3ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_way_ave_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f31d8a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.660236497870907"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference: average error of random guess\n",
    "100 * np.sum(np.abs(rand_ans - true_ans)) / len(true_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9af945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: worst case error of random guess\n",
    "# 100 * np.max(np.abs(rand_ans - true_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56880f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ced68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "599dddbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create a figure\u001b[39;00m\n\u001b[0;32m      2\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon_relationship_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtwo_way_ave_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdarkred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmathsf\u001b[39;49m\u001b[38;5;132;43;01m{MST}\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkersize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrivacy budget: $\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mepsilon$\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      9\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Error (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a figure\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "\n",
    "ax.plot(epsilon_relationship_set, two_way_ave_error, color='darkred', label = r'$\\mathsf{MST}$', marker = '*', markersize=8)\n",
    "\n",
    "\n",
    "ax.set_xlabel('Privacy budget: $\\epsilon$', fontsize=20)\n",
    "ax.set_ylabel('Average Error (%)', fontsize=20)\n",
    "# ax.grid()\n",
    "ax.legend(loc='upper right', fontsize=14, fancybox=True, edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim(0, 18)\n",
    "# ax.set_ylim(-0.001, 1.0)\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 12)\n",
    "ax.set_title('Movie Lens', size = 20, fontweight=\"bold\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727d7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cd09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
