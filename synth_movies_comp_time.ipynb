{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Title', 'Genres'], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Gender', \"Age\", \"Occupation\", \"Zipcode\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file_path, delimiter='::', header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dp_relational\n",
    "import dp_relational.data.movies\n",
    "import dp_relational.lib.synth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I demonstrate the sheer magnitude of the speedups I have implemented.\n",
    "\n",
    "\\- Ojas Gulati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dp_relational.data.movies.dataset\n",
    "\n",
    "# parameters\n",
    "\n",
    "n_syn1=776\n",
    "n_syn2=1208\n",
    "\n",
    "epsilon=3.0\n",
    "eps1=1.0\n",
    "eps2=1.0\n",
    "eps_rel = epsilon - eps1 - eps2\n",
    "\n",
    "k=2\n",
    "dmax=10 # TODO: kinda urgently, this one is a mess\n",
    "dataset = dataset(dmax)\n",
    "\n",
    "synth='mst'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 262144 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n",
      "Fitting with 294 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n"
     ]
    }
   ],
   "source": [
    "rel_dataset = dataset\n",
    "df1_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table1.df, n_syn1, synth, epsilon=eps1)\n",
    "df2_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table2.df, n_syn2, synth, epsilon=eps2)\n",
    "\n",
    "df_rel = rel_dataset.df_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External synthetic data generation takes 1:40 on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:59<00:00, 20.27it/s]\n"
     ]
    }
   ],
   "source": [
    "qm = dp_relational.lib.synth_data.QueryManagerBasic(rel_dataset, k=k, df1_synth=df1_synth, df2_synth=df2_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the Q matrix takes a very long time (about 2:30 min) and will often fail due to lack of memory: it is at least 7.6GB here (I know this from error messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:44<00:00, 94.47s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.21914012329676, 47.21272051652407)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 10\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_basic(qm, eps_rel, T=T, verbose=verbose)\n",
    "relationship_syn = dp_relational.lib.synth_data.make_synthetic_rel_table(qm, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm, relationship_syn)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 16:00 to run for 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_torch = dp_relational.lib.synth_data.QueryManagerTorch(rel_dataset, k=k,\n",
    "                                df1_synth=df1_synth, df2_synth=df2_synth, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:47<00:00,  9.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.838004993870826, 67.78316852462254)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 5\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch(\n",
    "    qm_torch, eps_rel, T=T, verbose=verbose, T_mirror=50)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the full QM-Torch training with 10 iters is done in 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ID_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ID_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# TODO: need to improve it!\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_relationship):\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# TODO: assert ID_1 and ID_2 correspond to index\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     ID1 \u001b[38;5;241m=\u001b[39m \u001b[43mqm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_rel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m     ID2 \u001b[38;5;241m=\u001b[39m qm\u001b[38;5;241m.\u001b[39mrel_dataset\u001b[38;5;241m.\u001b[39mdf_rel\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m qm\u001b[38;5;241m.\u001b[39mworkload_names:\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ID_1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "100 * np.sum(np.abs(qm.rand_ans - qm.true_ans)) / len(qm.true_ans)\n",
    "\n",
    "num_relationship = qm.rel_dataset.df_rel.shape[0]\n",
    "true_ans = np.zeros(qm.num_all_queries)\n",
    "\n",
    "\n",
    "# TODO: need to improve it!\n",
    "for i in range(num_relationship):\n",
    "    \n",
    "    # TODO: assert ID_1 and ID_2 correspond to index\n",
    "    \n",
    "    ID1 = qm.rel_dataset.df_rel.iloc[i][qm.rel_dataset.rel_id1_col]\n",
    "    \n",
    "    ID2 = qm.rel_dataset.df_rel.iloc[i][qm.rel_dataset.rel_id2_col]\n",
    "    \n",
    "    for w in qm.workload_names:\n",
    "        cols1 = w[0]\n",
    "        cols2 = w[1]\n",
    "        v1 = []\n",
    "        for c1 in cols1:\n",
    "            v1.append(qm.rel_dataset.table1.df.iloc[ID1][c1])\n",
    "            \n",
    "        v2 = []\n",
    "        for c2 in cols2:\n",
    "            v2.append(qm.rel_dataset.table2.df.iloc[ID2][c2])\n",
    "        \n",
    "        ind = qm.query_ind(w, [v1,v2])\n",
    "        true_ans[int(ind)] += 1\n",
    "        \n",
    "true_ans = true_ans/num_relationship\n",
    "true_ans\n",
    "qm.true_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:47<00:00,  1.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.6702276971616152, 16.422165474154205)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 30\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch_masked(\n",
    "    qm_torch, eps_rel, T=T, verbose=verbose)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "\n",
    "ave_error, max_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
