{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Title', 'Genres'], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Gender', \"Age\", \"Occupation\", \"Zipcode\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file_path, delimiter='::', header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dp_relational\n",
    "import dp_relational.data.movies\n",
    "import dp_relational.lib.synth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I demonstrate the sheer magnitude of the speedups I have implemented.\n",
    "\n",
    "\\- Ojas Gulati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dp_relational.data.movies.dataset\n",
    "\n",
    "# parameters\n",
    "\n",
    "n_syn1=776\n",
    "n_syn2=1208\n",
    "\n",
    "epsilon=3.0\n",
    "eps1=1.0\n",
    "eps2=1.0\n",
    "eps_rel = epsilon - eps1 - eps2\n",
    "\n",
    "k=2\n",
    "dmax=10 # TODO: kinda urgently, this one is a mess\n",
    "dataset = dataset(dmax)\n",
    "\n",
    "synth='mst'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 262144 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n",
      "Fitting with 294 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n"
     ]
    }
   ],
   "source": [
    "rel_dataset = dataset\n",
    "df1_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table1.df, n_syn1, synth, epsilon=eps1)\n",
    "df2_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table2.df, n_syn2, synth, epsilon=eps2)\n",
    "\n",
    "df_rel = rel_dataset.df_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External synthetic data generation takes 1:40 on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:59<00:00, 20.27it/s]\n"
     ]
    }
   ],
   "source": [
    "qm = dp_relational.lib.synth_data.QueryManagerBasic(rel_dataset, k=k, df1_synth=df1_synth, df2_synth=df2_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the Q matrix takes a very long time (about 2:30 min) and will often fail due to lack of memory: it is at least 7.6GB here (I know this from error messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [15:44<00:00, 94.47s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.21914012329676, 47.21272051652407)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 10\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_basic(qm, eps_rel, T=T, verbose=verbose)\n",
    "relationship_syn = dp_relational.lib.synth_data.make_synthetic_rel_table(qm, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm, relationship_syn)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 16:00 to run for 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_torch = dp_relational.lib.synth_data.QueryManagerTorch(rel_dataset, k=k,\n",
    "                                df1_synth=df1_synth, df2_synth=df2_synth, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:47<00:00,  9.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.086061284424308, 50.997518610421835)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 5\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch(\n",
    "    qm_torch, eps_rel, T=T, verbose=verbose, T_mirror=50)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the full QM-Torch training with 10 iters is done in 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.660236497870907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "100 * np.sum(np.abs(qm.rand_ans - qm.true_ans)) / len(qm.true_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:47<00:00,  1.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.6702276971616152, 16.422165474154205)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 30\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch_masked(\n",
    "    qm_torch, eps_rel, T=T, verbose=verbose)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "\n",
    "ave_error, max_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
