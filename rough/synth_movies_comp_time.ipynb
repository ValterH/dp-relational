{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Title', 'Genres'], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:37: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users_df = pd.read_csv(file_path, delimiter='::', header=None, names=['ID', 'Gender', \"Age\", \"Occupation\", \"Zipcode\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\data\\movies.py:42: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file_path, delimiter='::', header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], encoding='latin1', index_col=[0])\n",
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dp_relational\n",
    "import dp_relational.data.movies\n",
    "import dp_relational.lib.synth_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I demonstrate the sheer magnitude of the speedups I have implemented.\n",
    "\n",
    "\\- Ojas Gulati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dp_relational.data.movies.dataset\n",
    "\n",
    "# parameters\n",
    "\n",
    "n_syn1=776\n",
    "n_syn2=1208\n",
    "\n",
    "epsilon=3.0\n",
    "eps1=1.0\n",
    "eps2=1.0\n",
    "eps_rel = epsilon - eps1 - eps2\n",
    "\n",
    "k=2\n",
    "dmax=10 # TODO: kinda urgently, this one is a mess\n",
    "dataset = dataset(dmax)\n",
    "\n",
    "synth='mst'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\mbi\\__init__.py:15: UserWarning: MixtureInference disabled, please install jax and jaxlib\n",
      "  warnings.warn('MixtureInference disabled, please install jax and jaxlib')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting with 262144 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n",
      "Fitting with 294 dimensions\n",
      "Getting cliques\n",
      "Estimating marginals\n"
     ]
    }
   ],
   "source": [
    "rel_dataset = dataset\n",
    "df1_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table1.df, n_syn1, synth, epsilon=eps1)\n",
    "df2_synth = dp_relational.lib.synth_data.compute_single_table_synth_data(rel_dataset.table2.df, n_syn2, synth, epsilon=eps2)\n",
    "\n",
    "df_rel = rel_dataset.df_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External synthetic data generation takes 1:40 on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:36<00:00, 33.09it/s]\n"
     ]
    }
   ],
   "source": [
    "qm = dp_relational.lib.synth_data.QueryManagerBasic(rel_dataset, k=k, df1_synth=df1_synth, df2_synth=df2_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the Q matrix takes a very long time (about 2:30 min) and will often fail due to lack of memory: it is at least 7.6GB here (I know this from error messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:05<00:32, 32.92s/it]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.23 GiB for an array with shape (937408, 176) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 2\u001b[0m b_round \u001b[38;5;241m=\u001b[39m \u001b[43mdp_relational\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynth_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_relationship_vector_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m relationship_syn \u001b[38;5;241m=\u001b[39m dp_relational\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39msynth_data\u001b[38;5;241m.\u001b[39mmake_synthetic_rel_table(qm, b_round)\n\u001b[0;32m      4\u001b[0m ave_error, max_error \u001b[38;5;241m=\u001b[39m dp_relational\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39msynth_data\u001b[38;5;241m.\u001b[39mevaluate_synthetic_rel_table(qm, relationship_syn)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\lib\\synth_data.py:188\u001b[0m, in \u001b[0;36mlearn_relationship_vector_basic\u001b[1;34m(qm, epsilon_relationship, T, delta_relationship, verbose)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m Q[ind_low:(ind_high\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)]:\n\u001b[0;32m    186\u001b[0m             Q_set\u001b[38;5;241m.\u001b[39mappend(row\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m--> 188\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[43mmirror_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_ans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_mirror\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m n_relationship_synt\n\u001b[0;32m    191\u001b[0m b_round \u001b[38;5;241m=\u001b[39m expround(b)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\lib\\synth_data.py:123\u001b[0m, in \u001b[0;36mlearn_relationship_vector_basic.<locals>.mirror_descent\u001b[1;34m(Q, b, a, step_size, T_mirror)\u001b[0m\n\u001b[0;32m    121\u001b[0m iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Compute the gradient of the objective function\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Update using Mirror Descent\u001b[39;00m\n\u001b[0;32m    125\u001b[0m b \u001b[38;5;241m=\u001b[39m mirror_descent_update(b, grad)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\lib\\synth_data.py:115\u001b[0m, in \u001b[0;36mlearn_relationship_vector_basic.<locals>.mirror_descent.<locals>.gradient\u001b[1;34m(Q, b, a)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient\u001b[39m(Q, b, a):\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m@\u001b[39m (np\u001b[38;5;241m.\u001b[39mmatmul(Q, b) \u001b[38;5;241m-\u001b[39m a)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.23 GiB for an array with shape (937408, 176) and data type float64"
     ]
    }
   ],
   "source": [
    "T = 3\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_basic(qm, 1, T=T, verbose=verbose)\n",
    "relationship_syn = dp_relational.lib.synth_data.make_synthetic_rel_table(qm, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm, relationship_syn)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took 16:00 to run for 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_torch = dp_relational.lib.synth_data.QueryManagerTorch(rel_dataset, k=k,\n",
    "                                df1_synth=df1_synth, df2_synth=df2_synth, verbose=verbose)\n",
    "qm_torch.num_relationship *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:03<00:07,  3.67s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 59994112 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m----> 2\u001b[0m b_round \u001b[38;5;241m=\u001b[39m \u001b[43mdp_relational\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynth_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_relationship_vector_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqm_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_rel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_mirror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df_syn_rel \u001b[38;5;241m=\u001b[39m dp_relational\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39msynth_data\u001b[38;5;241m.\u001b[39mmake_synthetic_rel_table_sparse(qm_torch, b_round)\n\u001b[0;32m      5\u001b[0m ave_error, max_error \u001b[38;5;241m=\u001b[39m dp_relational\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39msynth_data\u001b[38;5;241m.\u001b[39mevaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\.venv\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\lib\\synth_data.py:239\u001b[0m, in \u001b[0;36mlearn_relationship_vector_torch\u001b[1;34m(qm, epsilon_relationship, T, T_mirror, num_workload_ite, delta_relationship, verbose, device)\u001b[0m\n\u001b[0;32m    235\u001b[0m         noisy_curr_ans \u001b[38;5;241m=\u001b[39m GM_torch(curr_true_answer, per_round_rho_rel, num_relationship)\n\u001b[0;32m    237\u001b[0m         noisy_ans \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([noisy_ans, noisy_curr_ans])\n\u001b[1;32m--> 239\u001b[0m         Q_set \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_cat_sparse_coo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mQ_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_Qmat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     b \u001b[38;5;241m=\u001b[39m mirror_descent_torch(Q_set, b, noisy_ans, step_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, T_mirror\u001b[38;5;241m=\u001b[39mT_mirror)\n\u001b[0;32m    243\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m*\u001b[39m n_relationship_synt\n",
      "File \u001b[1;32mc:\\C\\MIT\\Spring24\\UROP_P2\\code\\code\\dp_relational\\lib\\helpers.py:143\u001b[0m, in \u001b[0;36mtorch_cat_sparse_coo\u001b[1;34m(tensors, dim, is_coalesced)\u001b[0m\n\u001b[0;32m    140\u001b[0m new_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m    141\u001b[0m new_size[dim] \u001b[38;5;241m=\u001b[39m curr_shift\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mcat(values_list), size\u001b[38;5;241m=\u001b[39mnew_size)\u001b[38;5;241m.\u001b[39m_coalesced_(is_coalesced)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 59994112 bytes."
     ]
    }
   ],
   "source": [
    "T = 3\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch(\n",
    "    qm_torch, eps_rel * 4, T=T, verbose=verbose, T_mirror=50)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "ave_error, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qm_torch.num_relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, the full QM-Torch training with 10 iters is done in 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.68784119e-01, 6.40000000e-01, 1.60794045e-02, ...,\n",
       "       4.96277916e-04, 1.98511166e-04, 8.93300248e-04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "100 * np.sum(np.abs(qm.rand_ans - qm.true_ans)) / len(qm.true_ans)\n",
    "\n",
    "num_relationship = qm.rel_dataset.df_rel.shape[0]\n",
    "true_ans = np.zeros(qm.num_all_queries)\n",
    "\n",
    "\n",
    "# TODO: need to improve it!\n",
    "for i in range(num_relationship):\n",
    "    \n",
    "    # TODO: assert ID_1 and ID_2 correspond to index\n",
    "    \n",
    "    ID1 = qm.rel_dataset.df_rel.iloc[i][qm.rel_dataset.rel_id1_col]\n",
    "    \n",
    "    ID2 = qm.rel_dataset.df_rel.iloc[i][qm.rel_dataset.rel_id2_col]\n",
    "    \n",
    "    for w in qm.workload_names:\n",
    "        cols1 = w[0]\n",
    "        cols2 = w[1]\n",
    "        v1 = []\n",
    "        for c1 in cols1:\n",
    "            v1.append(qm.rel_dataset.table1.df.iloc[ID1][c1])\n",
    "            \n",
    "        v2 = []\n",
    "        for c2 in cols2:\n",
    "            v2.append(qm.rel_dataset.table2.df.iloc[ID2][c2])\n",
    "        \n",
    "        ind = qm.query_ind(w, [v1,v2])\n",
    "        true_ans[int(ind)] += 1\n",
    "        \n",
    "true_ans = true_ans/num_relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ans - qm.true_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:47<00:00,  1.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.6702276971616152, 16.422165474154205)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 30\n",
    "b_round = dp_relational.lib.synth_data.learn_relationship_vector_torch_masked(\n",
    "    qm_torch, eps_rel, T=T, verbose=verbose)\n",
    "df_syn_rel = dp_relational.lib.synth_data.make_synthetic_rel_table_sparse(qm_torch, b_round)\n",
    "ave_error, max_error = dp_relational.lib.synth_data.evaluate_synthetic_rel_table(qm_torch, df_syn_rel)\n",
    "\n",
    "ave_error, max_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
